# -*- coding: utf-8 -*-
"""DCGANs_CelebA_3_noises.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11CL8eJ9_r9_BSf1fGPAk-inHRPaSVOPP
"""

#pro speed up
gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)
  
from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

#%%script echo skipping
! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

import os

try:
  os.makedirs("results")
except FileExistsError:
  # directory already exists
  pass

try:
  os.makedirs("img_align_celeba")
  os.makedirs("img_align_celeba/img_align_celeba")
except FileExistsError:
  # directory already exists
  pass

#%%script echo skipping
! kaggle datasets download -d jessicali9530/celeba-dataset

#%%script echo skipping
! unzip celeba-dataset.zip

# Commented out IPython magic to ensure Python compatibility.
# %%script echo skipping
# os.listdir()
# os.listdir('img_align_celeba/img_align_celeba/')

#setup
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

for dirname, _, filenames in os.walk(''):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from matplotlib import pyplot as plt
import tensorflow as tf
from tqdm import tqdm
from PIL import Image as Img
from keras import Input
from keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout,Conv2DTranspose,BatchNormalization
from keras.models import Model, Sequential
from tensorflow.keras.optimizers import RMSprop
from keras import preprocessing

#%%script echo skipping
from tqdm import tqdm
from PIL import Image as Img

#Load and resize images
PIC_DIR = f'img_align_celeba/img_align_celeba/'

IMAGES_COUNT = 50000

ORIG_WIDTH = 178
ORIG_HEIGHT = 208
diff = (ORIG_HEIGHT - ORIG_WIDTH) // 2

WIDTH = 64
HEIGHT = 64

#crop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff) #for lanzcos filtering
#pic.thumbnail((WIDTH, HEIGHT), Image.LANCZOS) # for lanzcos filtering
#went with min max because I wasnt sure about the side effects
crop = (30, 55, 150, 175) #croping size for the image so that only the face at centre is obtained'

images = []
for pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):
    images.append( np.array((Img.open(PIC_DIR + pic_file).crop(crop)).resize((64,64))) ) #crop just the face

for i in range(len(images)):
    images[i] = ((images[i] - images[i].min())/(255 - images[i].min())) #min max normalization to 0 to 1 sigmoid. 255 is max
    images[i] = images[i]*2 - 1  #need to scale it to -1 to 1 for tanh
    
images = np.array(images) 

len(images)

#%%script echo skipping
#Display first 25 images
#note there is an issue with colab with GPU right now
#bug is that you cant suppress warning
#https://stackoverflow.com/questions/9031783/hide-all-warnings-in-ipython
#warning are caused by tanh scaling, but matplotlib handles it just fine
import warnings
warnings.filterwarnings('ignore')
warnings.simplefilter('ignore')

plt.figure(1, figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.imshow(images[i])
    plt.axis('off')
plt.show()

#generator
latent_noise_shape = 100
generator=Sequential()
generator.add(Dense(4*4*512,input_shape=[latent_noise_shape]))
generator.add(Reshape([4,4,512]))
generator.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding="same", activation='relu'))
generator.add(BatchNormalization())
generator.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding="same", activation='relu'))
generator.add(BatchNormalization())
generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding="same", activation='relu'))
generator.add(BatchNormalization())
generator.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding="same", activation='tanh'))
#went standard DCGANs with relu activation and batch normailization 
#note tanh can instead be sigmoid, but you will need to comment out the tanh scaling inthe image processing
#tanh seems to converge better than sigmoid from my own tests
#theory from DCGANs paper as well as: https://mvschamanth.medium.com/activation-functions-why-tanh-outperforms-logistic-sigmoid-3f26469ac0d1

#discriminator
discriminator = Sequential()
discriminator.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=[64,64, 3]))
discriminator.add(LeakyReLU(alpha=0.2))
discriminator.add(Dropout(0.4))
discriminator.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))
discriminator.add(LeakyReLU(alpha=0.2))
discriminator.add(Dropout(0.4))
discriminator.add(Flatten())
discriminator.add(Dense(1, activation='sigmoid'))
#I had to downgrade the discriminator to the one above as the discriminator was winning too hard
#added dropouts and made the system shallow to make it weaker, also went with 3,3 instead of 4,4
#saving the bottom discriminator as it does when if I load a saved generator
#below is a stronger discriminator for testing later
#note 2, I save the weights for the generator after 300 cycles then used those weights against 
#the strong discriminator. The sytem collapsed. 
#more tests will need to be run to get this to work

# discriminator=Sequential()
# discriminator.add(Conv2D(32, kernel_size=4, strides=2, padding="same",input_shape=[64,64, 3]))
# discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding="same"))
# discriminator.add(LeakyReLU(0.2))
# discriminator.add(BatchNormalization())
# discriminator.add(Dropout(0.4))
# discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding="same"))
# discriminator.add(LeakyReLU(0.2))
# discriminator.add(BatchNormalization())
# discriminator.add(Dropout(0.4))
# discriminator.add(Conv2D(256, kernel_size=4, strides=2, padding="same"))
# discriminator.add(LeakyReLU(0.2))
# discriminator.add(Flatten())
# discriminator.add(Dropout(0.4))
# discriminator.add(Dense(1,activation='sigmoid'))

# optimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)
# discriminator.compile(optimizer=optimizer, loss='binary_crossentropy')

#generator to discriminator cycle
GAN = Sequential([generator,discriminator])
discriminator.compile(optimizer='adam',loss='binary_crossentropy')
discriminator.trainable = False
GAN.compile(optimizer='adam',loss='binary_crossentropy')
GAN.layers

#OPTIMIZER
#I tried RMS zero_grad and adam. Adam works best. This agrees with: https://towardsdatascience.com/understanding-and-optimizing-gans-going-back-to-first-principles-e5df8835ae18
# sample RMS
# optimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)
# GAN.compile(optimizer=optimizer, loss='binary_crossentropy')

#LOSS
#I did not get enough time to try wasserstein loss, but it should in theory work better than entropy
#https://machinelearningmastery.com/how-to-implement-wasserstein-loss-for-generative-adversarial-networks/

# part of my experiment to introduce noise per epoch.
# never got this to work consistently 
def get_noise(epoch):
  if epoch < 10:
    return 0.05
  else:
    return 0.0

epochs = 300  #choose 300 due to time constraints and because others had success with this
batch_size = 128
#note on the batch, 200 batch of 250 cycles runs faster than 128 batch at 390 cycles. 
#In fact the larger the batch (as long as you have the ram) the faster
#I went with 128 as an increased number of cycles does seem to help the model
D_loss = [] #total discriminator loss
G_loss = [] #total generator loss
Df_loss = [] #discriminator loss fake
Dr_loss = [] #discriminator loss real

with tf.device('/gpu:0'):
 for epoch in range(epochs):
    print(f"Currently on Epoch {epoch+1}")
    
    # 1 epoch is a complete cycle of all 50000 images
    # each patch is 128 at a time or 390 batches per epoch
    for i in range(images.shape[0]//batch_size):
        
        if (i)%100 == 0:
            print(f"\tCurrently on batch number {i} of {len(images)//batch_size}")


        #note the commented out noise I added to the labels. Never got that to work properly
        #more experimentation needed    
        noise=np.random.uniform(-1,1,size=[batch_size,latent_noise_shape])
        
        gen_image = generator.predict_on_batch(noise)
        
        train_dataset = images[i*batch_size:(i+1)*batch_size]
        
        #train on real image
        real_label=np.ones(shape=(batch_size,1))
        #real_label += get_noise(epoch)* np.random.random(train_label.shape)
        discriminator.trainable = True
        dr_loss = discriminator.train_on_batch(train_dataset,real_label)
        
        #train on fake image
        fake_label=np.zeros(shape=(batch_size,1))
        #fake_label += get_noise(epoch)* np.random.random(train_label.shape)
        df_loss = discriminator.train_on_batch(gen_image,fake_label)
        
        noise=np.random.uniform(-1,1,size=[batch_size,latent_noise_shape])
        discriminator.trainable = False
        #train the generator
        g_loss = GAN.train_on_batch(noise, real_label)

        #shelving for inconsistent results
        #I rewrote the logic for the generator and discriminator
        #In particular I concatonated the real and fake images for the discriminator
        #into 1 run instead of two. This speeds up the performance of the runs
        #the only downside is that I lose the ability to see both the separate discriminator
        #losses for real and fake, itinstead combines, but its worth the performance improvement
        #I also lose the ability to not run the discriminator, but from experience this
        #doesnt matter as you always want to run the discriminator
        #--------------------------------------------------------------------------------------
        # #discriminator loss
        # true_label = np.ones(shape=(batch_size,1))
        # # noise_true_label = np.ones(shape=(batch_size,1))
        # # noise_true_label += get_noise(epoch)* np.random.random(true_label.shape)

        # false_label = np.zeros(shape=(batch_size,1))
        # # noise_false_label = np.zeros(shape=(batch_size,1))
        # # noise_false_label += get_noise(epoch)* np.random.random(true_label.shape)

        # comb_labels = np.concatenate([true_label, false_label])
        # comb_img = np.concatenate([train_dataset, gen_image])

        # discriminator.trainable = True
        # d_loss = discriminator.train_on_batch(comb_img, comb_labels)

        # #generator loss
        # noise=np.random.uniform(-1,1,size=[batch_size,latent_noise_shape])
        # true_label = np.ones(shape=(batch_size,1))

        # discriminator.trainable = False
        # g_loss = GAN.train_on_batch(noise, true_label)
        #--------------------------------------------------------------------------------------

        #append loss
        D_loss.append(dr_loss+df_loss)
        Dr_loss.append(dr_loss)
        Df_loss.append(df_loss)
        G_loss.append(g_loss)

    #generate result images     
    if (epoch % 5 == 0) or (epoch == epochs-1):
        samples = 25
        for k in range(samples):
            plt.subplot(5, 5, k+1)
            plt.imshow(gen_image[k].reshape(64,64,3))
            plt.xticks([])
            plt.yticks([])
        plt.tight_layout()

        #save file
        numbering = '{0:03}'.format(epoch)
        plt.savefig(f"results/epoch-{numbering}.png")

        #must be after save file
        plt.show()

    print('Epoch: %d,  Loss: D_real = %.3f, D_fake = %.3f,  G = %.3f' %   (epoch+1, dr_loss, df_loss, g_loss))
print('Training is complete')

#save weights
GAN.save_weights('gan_01.h5')
discriminator.save_weights('dis_01.h5')
generator.save_weights('gen_01.h5')

plt.figure(1, figsize=(12, 8))
plt.subplot(121)
plt.plot(D_loss, color='blue')
plt.xlabel('batches')
plt.ylabel('Discriminator Loss')
plt.subplot(122)
plt.plot(G_loss, color='red')
plt.xlabel('batches')
plt.ylabel('Generator Loss')
plt.show()

plt.figure(figsize=(10,10))
plt.plot(Dr_loss,color='red',label='Discriminator_Real_Loss')
plt.plot(Df_loss,color='blue',label='Discriminator_Fake_Loss')
plt.legend()
plt.xlabel('total batches')
plt.ylabel('loss')
plt.title('Loss per batch')
plt.show()

plt.figure(figsize=(10,10))
plt.plot(G_loss,color='red',label='Generator_loss')
plt.plot(D_loss,color='blue',label='Discriminator_loss')
plt.legend()
plt.xlabel('total batches')
plt.ylabel('loss')
plt.title('Loss per batch')
plt.show()

!zip -r /content/results.zip /content/results/

from google.colab import files
# files.download("results.zip")

#note home is /content/

len(D_loss)

# files.download("dis_01.h5")
# files.download("gan_01.h5")
# files.download("gen_01.h5")

generator.load_weights('gen_01.h5')
samples = 25
noise=np.random.uniform(-1,1,size=[25,latent_noise_shape])
im=generator.predict(noise) 
for k in range(samples):
  plt.subplot(5, 5, k+1)
  plt.imshow(im[k].reshape(64,64,3))
  plt.xticks([])
  plt.yticks([])
plt.tight_layout()

#save file
numbering = '{0:03}'.format(epoch)
plt.savefig(f"results/epoch-{numbering}.png")

#must be after save file
plt.show()